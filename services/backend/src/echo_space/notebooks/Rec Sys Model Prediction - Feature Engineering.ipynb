{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1543c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,  GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b95ae87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = pd.read_csv(\"../services/backend/seed_data/data/nov_19_dump/content.csv\")\n",
    "engagement = pd.read_csv(\"../services/backend/seed_data/data/nov_19_dump/engagement.csv\")\n",
    "gcm_ = pd.read_csv(\"../services/backend/seed_data/data/nov_19_dump/generated_content_metadata.csv\")\n",
    "target = pd.read_csv(\"../services/backend/processed_data/target.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c4dbd",
   "metadata": {},
   "source": [
    "## Create a User Feature Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf12cc",
   "metadata": {},
   "source": [
    "<li> For the prediction part, we can easily retrieve the table for further feature engineering </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "744b7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Features\n",
    "def convert_embedding(row):\n",
    "    if row[\"engagement_value\"] == 0:\n",
    "        row[\"prompt_embedding\"] = [x * -1 for x in row[\"prompt_embedding\"]]\n",
    "    return row[\"prompt_embedding\"]\n",
    "\n",
    "\n",
    "def user_embedding(gcm,target):\n",
    "    gcm_tmp = pd.merge(gcm[[\"content_id\",\"prompt_embedding\"]],target,on = \"content_id\")\n",
    "    gcm_tmp[\"embedding_new\"] = gcm_tmp[[\"prompt_embedding\",\"engagement_value\"]].apply(convert_embedding,axis=1)\n",
    "    ## Explode list to multiple columns\n",
    "    usr_embed = pd.DataFrame(gcm_tmp[\"embedding_new\"].tolist())\n",
    "    usr_embed = usr_embed.add_prefix('user_embed_')\n",
    "    usr_embed = pd.concat([gcm_tmp[\"user_id\"],usr_embed],axis=1)\n",
    "    # Get the mean content embedding as the user embedding \n",
    "    usr_embed = usr_embed.groupby(\"user_id\").mean().reset_index()\n",
    "    ## Get embedding combined into one column to further calculate cosine similarity\n",
    "    usr_embed['embed_combined']= usr_embed.drop(\"user_id\",axis=1).values.tolist()\n",
    "    return usr_embed[['user_id', 'embed_combined']]\n",
    "\n",
    "def add_user_features(target,usr_embed):\n",
    "    ## Add user like rate and average engagement time features\n",
    "    user_info1 = target.groupby(\"user_id\").mean()[\"engagement_value\"].rename(\"User_Like_Rate\").reset_index()\n",
    "    user_info2 = engagement[engagement[\"engagement_type\"] == \"MillisecondsEngagedWith\"]\\\n",
    "                .groupby(\"user_id\").mean()[\"engagement_value\"].rename(\"User_Avg_Time_Millisec\").reset_index()\n",
    "\n",
    "    user_info = pd.merge(user_info1,user_info2,how = \"left\", on=\"user_id\")\n",
    "    user_info = pd.merge(user_info,usr_embed, on = \"user_id\")#.drop(\"embed_combined\",axis=1)\n",
    "    return user_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d74afbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string into corresponding embedding list\n",
    "gcm = gcm_.copy()\n",
    "gcm[\"prompt_embedding\"] = gcm[\"prompt_embedding\"].apply(lambda x:eval(x))\n",
    "\n",
    "prompt_embedding = np.array(gcm['prompt_embedding'].tolist())\n",
    "prompt_embedding = prompt_embedding[:,:32].tolist()\n",
    "gcm[\"prompt_embedding\"] = prompt_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75164abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_embed = user_embedding(gcm,target)\n",
    "user_info = add_user_features(target,usr_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48439e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.to_parquet(\"../services/backend/processed_data/User_Features.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc84345",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_info\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser_Features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_info' is not defined"
     ]
    }
   ],
   "source": [
    "user_info.to_csv(\"User_Features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef439336",
   "metadata": {},
   "source": [
    "## Create a Item Feature Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8424cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the text\n",
    "def decontraction(phrase):\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"he's\", \"he is\", phrase)\n",
    "    phrase = re.sub(r\"there's\", \"there is\", phrase)\n",
    "    phrase = re.sub(r\"We're\", \"We are\", phrase)\n",
    "    phrase = re.sub(r\"That's\", \"That is\", phrase)\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"they're\", \"they are\", phrase)\n",
    "    phrase = re.sub(r\"Can't\", \"Cannot\", phrase)\n",
    "    phrase = re.sub(r\"wasn't\", \"was not\", phrase)\n",
    "    phrase = re.sub(r\"don\\x89Ûªt\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"donãât\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"aren't\", \"are not\", phrase)\n",
    "    phrase = re.sub(r\"isn't\", \"is not\", phrase)\n",
    "    phrase = re.sub(r\"What's\", \"What is\", phrase)\n",
    "    phrase = re.sub(r\"haven't\", \"have not\", phrase)\n",
    "    phrase = re.sub(r\"hasn't\", \"has not\", phrase)\n",
    "    phrase = re.sub(r\"There's\", \"There is\", phrase)\n",
    "    phrase = re.sub(r\"He's\", \"He is\", phrase)\n",
    "    phrase = re.sub(r\"It's\", \"It is\", phrase)\n",
    "    phrase = re.sub(r\"You're\", \"You are\", phrase)\n",
    "    phrase = re.sub(r\"I'M\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"shouldn't\", \"should not\", phrase)\n",
    "    phrase = re.sub(r\"wouldn't\", \"would not\", phrase)\n",
    "    phrase = re.sub(r\"i'm\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"I\\x89Ûªm\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"I'm\", \"I am\", phrase)\n",
    "    phrase = re.sub(r\"Isn't\", \"is not\", phrase)\n",
    "    phrase = re.sub(r\"Here's\", \"Here is\", phrase)\n",
    "    phrase = re.sub(r\"you've\", \"you have\", phrase)\n",
    "    phrase = re.sub(r\"you\\x89Ûªve\", \"you have\", phrase)\n",
    "    phrase = re.sub(r\"we're\", \"we are\", phrase)\n",
    "    phrase = re.sub(r\"what's\", \"what is\", phrase)\n",
    "    phrase = re.sub(r\"couldn't\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"we've\", \"we have\", phrase)\n",
    "    phrase = re.sub(r\"it\\x89Ûªs\", \"it is\", phrase)\n",
    "    phrase = re.sub(r\"doesn\\x89Ûªt\", \"does not\", phrase)\n",
    "    phrase = re.sub(r\"It\\x89Ûªs\", \"It is\", phrase)\n",
    "    phrase = re.sub(r\"Here\\x89Ûªs\", \"Here is\", phrase)\n",
    "    phrase = re.sub(r\"who's\", \"who is\", phrase)\n",
    "    phrase = re.sub(r\"I\\x89Ûªve\", \"I have\", phrase)\n",
    "    phrase = re.sub(r\"y'all\", \"you all\", phrase)\n",
    "    phrase = re.sub(r\"can\\x89Ûªt\", \"cannot\", phrase)\n",
    "    phrase = re.sub(r\"would've\", \"would have\", phrase)\n",
    "    phrase = re.sub(r\"it'll\", \"it will\", phrase)\n",
    "    phrase = re.sub(r\"we'll\", \"we will\", phrase)\n",
    "    phrase = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", phrase)\n",
    "    phrase = re.sub(r\"We've\", \"We have\", phrase)\n",
    "    phrase = re.sub(r\"he'll\", \"he will\", phrase)\n",
    "    phrase = re.sub(r\"Y'all\", \"You all\", phrase)\n",
    "    phrase = re.sub(r\"Weren't\", \"Were not\", phrase)\n",
    "    phrase = re.sub(r\"Didn't\", \"Did not\", phrase)\n",
    "    phrase = re.sub(r\"they'll\", \"they will\", phrase)\n",
    "    phrase = re.sub(r\"they'd\", \"they would\", phrase)\n",
    "    phrase = re.sub(r\"DON'T\", \"DO NOT\", phrase)\n",
    "    phrase = re.sub(r\"That\\x89Ûªs\", \"That is\", phrase)\n",
    "    phrase = re.sub(r\"they've\", \"they have\", phrase)\n",
    "    phrase = re.sub(r\"i'd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"should've\", \"should have\", phrase)\n",
    "    phrase = re.sub(r\"You\\x89Ûªre\", \"You are\", phrase)\n",
    "    phrase = re.sub(r\"where's\", \"where is\", phrase)\n",
    "    phrase = re.sub(r\"Don\\x89Ûªt\", \"Do not\", phrase)\n",
    "    phrase = re.sub(r\"we'd\", \"we would\", phrase)\n",
    "    phrase = re.sub(r\"i'll\", \"I will\", phrase)\n",
    "    phrase = re.sub(r\"weren't\", \"were not\", phrase)\n",
    "    phrase = re.sub(r\"They're\", \"They are\", phrase)\n",
    "    phrase = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", phrase)\n",
    "    phrase = re.sub(r\"you\\x89Ûªll\", \"you will\", phrase)\n",
    "    phrase = re.sub(r\"I\\x89Ûªd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"let's\", \"let us\", phrase)\n",
    "    phrase = re.sub(r\"it's\", \"it is\", phrase)\n",
    "    phrase = re.sub(r\"can't\", \"cannot\", phrase)\n",
    "    phrase = re.sub(r\"don't\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"you're\", \"you are\", phrase)\n",
    "    phrase = re.sub(r\"i've\", \"I have\", phrase)\n",
    "    phrase = re.sub(r\"that's\", \"that is\", phrase)\n",
    "    phrase = re.sub(r\"i'll\", \"I will\", phrase)\n",
    "    phrase = re.sub(r\"doesn't\", \"does not\",phrase)\n",
    "    phrase = re.sub(r\"i'd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"didn't\", \"did not\", phrase)\n",
    "    phrase = re.sub(r\"ain't\", \"am not\", phrase)\n",
    "    phrase = re.sub(r\"you'll\", \"you will\", phrase)\n",
    "    phrase = re.sub(r\"I've\", \"I have\", phrase)\n",
    "    phrase = re.sub(r\"Don't\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"I'll\", \"I will\", phrase)\n",
    "    phrase = re.sub(r\"I'd\", \"I would\", phrase)\n",
    "    phrase = re.sub(r\"Let's\", \"Let us\", phrase)\n",
    "    phrase = re.sub(r\"you'd\", \"You would\", phrase)\n",
    "    phrase = re.sub(r\"It's\", \"It is\", phrase)\n",
    "    phrase = re.sub(r\"Ain't\", \"am not\", phrase)\n",
    "    phrase = re.sub(r\"Haven't\", \"Have not\", phrase)\n",
    "    phrase = re.sub(r\"Could've\", \"Could have\", phrase)\n",
    "    phrase = re.sub(r\"youve\", \"you have\", phrase)  \n",
    "    phrase = re.sub(r\"donå«t\", \"do not\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in list(string.punctuation):\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "    \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = decontraction(text)\n",
    "    text = text.lower()\n",
    "    text = remove_punctuations(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "## Get tabular feature and sentiment of the text\n",
    "def text_features(df,col):\n",
    "    df[\"num_words\"] = df[col].apply(lambda x: len(str(x).split()))\n",
    "    df[\"num_chars\"] = df[col].apply(lambda x: len(str(x)))\n",
    "    df[\"num_stopwords\"] = df[col].apply(lambda x: len([w for w in str(x).lower().split() if w in stopwords.words('english')]))\n",
    "    df[\"num_punctuations\"] = df[col].apply(lambda x: len([c for c in str(x) if c in list(string.punctuation)]))\n",
    "    df[\"mean_word_len\"] = df[col].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "    #Sentiment: lies between [-1,1], -1 defines a negative sentiment and 1 defines a positive sentiment.\n",
    "    df[\"polarity\"] = df[col].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "    #The higher subjectivity means that the text contains personal opinion rather than factual information.\n",
    "    df[\"subjectivity\"] = df[col].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "    return df\n",
    "\n",
    "def add_content_like(gcm,target):\n",
    "    content_like = target.groupby(\"content_id\").mean()[\"engagement_value\"].rename(\"Like Rate\").reset_index()\n",
    "    avg_like_rt = content_like[\"Like Rate\"].mean()\n",
    "    slt_content = target.groupby(\"content_id\").count()[\"user_id\"].rename(\"expose_cnt\").reset_index()\n",
    "    slt_content = slt_content[slt_content[\"expose_cnt\"]>1].drop(\"expose_cnt\",axis=1)\n",
    "    content_like = pd.merge(content_like, slt_content, how = \"left\")\n",
    "    # Use avg like rate to fill the content exposed to only one user\n",
    "    content_like = content_like.fillna(avg_like_rt)\n",
    "    # Join two dataframes to get the general like rate of the content\n",
    "    gcm = pd.merge(gcm,content_like,on=\"content_id\",how = \"left\") # Keep the NA without filling the avg like rate\n",
    "    return gcm\n",
    "\n",
    "def combine_content(gcm,gcm_useful_cols):\n",
    "    ## Explode content embedding list to multiple columns\n",
    "    content_embed = pd.DataFrame(gcm[\"prompt_embedding\"].tolist())\n",
    "    content_embed = content_embed.add_prefix('content_embed_')\n",
    "    content_embed = pd.concat([gcm[\"content_id\"],content_embed],axis=1).drop_duplicates()\n",
    "    # Join two dataframes to get full content features\n",
    "    content_features = pd.merge(gcm[gcm_useful_cols],content_embed, on = \"content_id\", how=\"left\")\n",
    "    return content_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "580ced97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the text\n",
    "gcm['original_prompt'] = gcm['original_prompt'].apply(clean_text)\n",
    "## Get text features\n",
    "gcm = text_features(gcm, \"original_prompt\")\n",
    "gcm = add_content_like(gcm,target)\n",
    "\n",
    "gcm_useful_cols = ['content_id', 'num_inference_steps', 'guidance_scale','source',\n",
    "                   'num_words','num_chars', 'num_stopwords', 'num_punctuations',\n",
    "                   'mean_word_len', 'polarity', 'subjectivity','Like Rate', 'prompt_embedding'] # Keep prompt_embedding for further cos similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "22a16e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features = combine_content(gcm,gcm_useful_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d179b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = content_features.iloc[:, :13]\n",
    "# dft = dft.drop('source', axis=1)\n",
    "# dft = dft.drop('prompt_embedding', axis=1)\n",
    "# dft.iloc[:,-32:] = dft.iloc[:,-32:].astype('float16')\n",
    "dft.to_parquet('../services/backend/processed_data/Content_Features.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e963ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features_cols = content_features.columns.tolist()[:12]\n",
    "user_features_cols = user_features.columns.tolist()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0daa5",
   "metadata": {},
   "source": [
    "## Build feature generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d33dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cosine(user_id,content_id,user_features,content_features):\n",
    "    \n",
    "    slct_user_feature = user_features[user_features[\"user_id\"]== user_id]\n",
    "    slct_content_feature = content_features[content_features[\"content_id\"]== content_id]\n",
    "    user_embedding_lst = slct_user_feature[\"embed_combined\"].tolist()[0]\n",
    "    content_feature_lst = slct_content_feature[\"prompt_embedding\"].tolist()[0]\n",
    "    a,b = user_embedding_lst, content_feature_lst\n",
    "    cosine_similarity = dot(a, b)/(norm(a)*norm(b))\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de6587e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = engagement.user_id.unique().tolist()\n",
    "all_contents = content.id.unique().tolist()\n",
    "from itertools import product\n",
    "\n",
    "user_item_df = pd.DataFrame(list(product(all_users, all_contents)), columns = ['user_id', 'content_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2cfd947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(user_id,content_id,user_features,content_features):#,user_path= \"User_Features.parquet\",content_path = \"Content_Features.parquet\" ):\n",
    "    slct_user_feature = user_features[user_features[\"user_id\"]== user_id]\n",
    "    slct_content_feature = content_features[content_features[\"content_id\"]== content_id]\n",
    "    user_embedding_lst = slct_user_feature[\"embed_combined\"].tolist()[0]\n",
    "    content_feature_lst = slct_content_feature[\"prompt_embedding\"].tolist()[0]\n",
    "    a,b = user_embedding_lst, content_feature_lst\n",
    "    cosine_similarity = dot(a, b)/(norm(a)*norm(b))\n",
    "    full_features = slct_user_feature.drop([\"user_id\",\"embed_combined\"],axis=1).values.tolist()[0]\\\n",
    "                    + slct_content_feature.drop([\"content_id\",\"source\",\"prompt_embedding\"],axis=1).values.tolist()[0] \\\n",
    "                    + [cosine_similarity]\n",
    "\n",
    "    \n",
    "    return full_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6b62522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_path = \"../services/backend/processed_data/User_Features.parquet\"\n",
    "content_path = \"../services/backend/processed_data/Content_Features.parquet\"\n",
    "user_features_ = pd.read_parquet(user_path)\n",
    "content_features_ = pd.read_parquet(content_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "119328a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_ = pd.concat([user_features_, pd.DataFrame(user_features_[\"embed_combined\"].tolist()).add_prefix('emb_')], axis=1)\n",
    "content_features_ = pd.concat([content_features_, pd.DataFrame(content_features_[\"prompt_embedding\"].tolist()).add_prefix('emb_')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ee314740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107705, 45)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_features_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc818353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_df = user_item_df[[\"user_id\",\"content_id\"]].apply(lambda row: gen_cosine(row[\"user_id\"],row[\"content_id\"],user_features,content_features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "15dbdee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../services/backend/processed_data/train.csv\")\n",
    "test = pd.read_csv(\"../services/backend/processed_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "05f09250",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"user_id\",\"content_id\"]].apply(lambda row: generate_features(row[\"user_id\"],row[\"content_id\"],user_features_,content_features_),axis=1)\n",
    "X_train = pd.DataFrame(X_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "807687b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"engagement_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f1b1759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[[\"user_id\",\"content_id\"]].apply(lambda row: generate_features(row[\"user_id\"],row[\"content_id\"],user_features_,content_features_),axis=1)\n",
    "X_test = pd.DataFrame(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "35e79ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[\"engagement_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b5c608e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f31fa5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.01978917e-05, 9.99909802e-01],\n",
       "       [9.99970595e-01, 2.94049651e-05],\n",
       "       [7.47890756e-01, 2.52109244e-01],\n",
       "       ...,\n",
       "       [9.77124234e-01, 2.28757663e-02],\n",
       "       [9.99975656e-01, 2.43440029e-05],\n",
       "       [9.99954244e-01, 4.57559627e-05]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6e9b44af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../services/backend/src/recommendation_system/ml_models/lgbm.pkl']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lgb.save(model, '../services/backend/src/recommendation_system/ml_models/lgbm.pkl', num_iteration = NULL)\n",
    "import joblib\n",
    "# save model\n",
    "joblib.dump(model, '../services/backend/src/recommendation_system/ml_models/lgbm.pkl')\n",
    "# # load model\n",
    "# gbm_pickle = joblib.load('lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e32ea8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = joblib.load('../services/backend/src/recommendation_system/ml_models/lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5fae0e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b2f1d30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437773</td>\n",
       "      <td>89446.786957</td>\n",
       "      <td>6.728266</td>\n",
       "      <td>-2.205232</td>\n",
       "      <td>-0.935654</td>\n",
       "      <td>0.414398</td>\n",
       "      <td>-0.722790</td>\n",
       "      <td>-0.170461</td>\n",
       "      <td>-0.396117</td>\n",
       "      <td>-0.478514</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.375868</td>\n",
       "      <td>-15.747827</td>\n",
       "      <td>10.470771</td>\n",
       "      <td>0.691198</td>\n",
       "      <td>-2.789990</td>\n",
       "      <td>1.827842</td>\n",
       "      <td>-0.277631</td>\n",
       "      <td>1.139680</td>\n",
       "      <td>3.945075</td>\n",
       "      <td>-0.574410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513393</td>\n",
       "      <td>3834.459649</td>\n",
       "      <td>10.334824</td>\n",
       "      <td>-3.120607</td>\n",
       "      <td>-0.430606</td>\n",
       "      <td>-0.189135</td>\n",
       "      <td>-1.491082</td>\n",
       "      <td>-1.161160</td>\n",
       "      <td>-0.883617</td>\n",
       "      <td>1.476626</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.424211</td>\n",
       "      <td>-14.681874</td>\n",
       "      <td>1.536202</td>\n",
       "      <td>2.356138</td>\n",
       "      <td>5.213597</td>\n",
       "      <td>5.147564</td>\n",
       "      <td>7.545617</td>\n",
       "      <td>5.880928</td>\n",
       "      <td>-2.953583</td>\n",
       "      <td>-0.545915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347561</td>\n",
       "      <td>10888.293103</td>\n",
       "      <td>4.592510</td>\n",
       "      <td>-3.190515</td>\n",
       "      <td>-1.007697</td>\n",
       "      <td>3.566104</td>\n",
       "      <td>-0.926311</td>\n",
       "      <td>0.800057</td>\n",
       "      <td>-1.553255</td>\n",
       "      <td>0.150828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.404554</td>\n",
       "      <td>-7.091844</td>\n",
       "      <td>-5.271067</td>\n",
       "      <td>-4.057229</td>\n",
       "      <td>-2.413814</td>\n",
       "      <td>0.685560</td>\n",
       "      <td>14.102049</td>\n",
       "      <td>15.216167</td>\n",
       "      <td>2.129391</td>\n",
       "      <td>-0.436742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355908</td>\n",
       "      <td>58446.510204</td>\n",
       "      <td>9.826862</td>\n",
       "      <td>-1.359778</td>\n",
       "      <td>1.603947</td>\n",
       "      <td>1.285903</td>\n",
       "      <td>-1.549141</td>\n",
       "      <td>1.407438</td>\n",
       "      <td>-0.527707</td>\n",
       "      <td>-1.540423</td>\n",
       "      <td>...</td>\n",
       "      <td>6.423792</td>\n",
       "      <td>0.420492</td>\n",
       "      <td>9.965358</td>\n",
       "      <td>-4.019853</td>\n",
       "      <td>17.191104</td>\n",
       "      <td>1.620610</td>\n",
       "      <td>9.487975</td>\n",
       "      <td>2.405741</td>\n",
       "      <td>9.072886</td>\n",
       "      <td>0.547553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.482927</td>\n",
       "      <td>32380.040541</td>\n",
       "      <td>17.349594</td>\n",
       "      <td>1.228321</td>\n",
       "      <td>-0.375397</td>\n",
       "      <td>-2.452161</td>\n",
       "      <td>-3.844825</td>\n",
       "      <td>-0.479502</td>\n",
       "      <td>-2.034023</td>\n",
       "      <td>-1.296189</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.284498</td>\n",
       "      <td>9.315584</td>\n",
       "      <td>-10.445529</td>\n",
       "      <td>11.428464</td>\n",
       "      <td>0.595655</td>\n",
       "      <td>1.485687</td>\n",
       "      <td>-1.503689</td>\n",
       "      <td>2.343183</td>\n",
       "      <td>0.056319</td>\n",
       "      <td>-0.736785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19463</th>\n",
       "      <td>0.437773</td>\n",
       "      <td>89446.786957</td>\n",
       "      <td>6.728266</td>\n",
       "      <td>-2.205232</td>\n",
       "      <td>-0.935654</td>\n",
       "      <td>0.414398</td>\n",
       "      <td>-0.722790</td>\n",
       "      <td>-0.170461</td>\n",
       "      <td>-0.396117</td>\n",
       "      <td>-0.478514</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.846691</td>\n",
       "      <td>-2.671703</td>\n",
       "      <td>-0.628226</td>\n",
       "      <td>18.510978</td>\n",
       "      <td>-10.815182</td>\n",
       "      <td>-0.016847</td>\n",
       "      <td>-7.861359</td>\n",
       "      <td>-7.371767</td>\n",
       "      <td>-34.196477</td>\n",
       "      <td>0.632159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19464</th>\n",
       "      <td>0.181338</td>\n",
       "      <td>3442.966292</td>\n",
       "      <td>1.844459</td>\n",
       "      <td>2.867678</td>\n",
       "      <td>2.187282</td>\n",
       "      <td>4.048394</td>\n",
       "      <td>-1.494160</td>\n",
       "      <td>0.845086</td>\n",
       "      <td>1.209595</td>\n",
       "      <td>-0.510142</td>\n",
       "      <td>...</td>\n",
       "      <td>4.637885</td>\n",
       "      <td>3.869178</td>\n",
       "      <td>2.353058</td>\n",
       "      <td>-4.430796</td>\n",
       "      <td>3.717093</td>\n",
       "      <td>-6.779565</td>\n",
       "      <td>9.317777</td>\n",
       "      <td>-3.288596</td>\n",
       "      <td>-0.027603</td>\n",
       "      <td>-0.035675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19465</th>\n",
       "      <td>0.500595</td>\n",
       "      <td>4623.850480</td>\n",
       "      <td>14.910786</td>\n",
       "      <td>-4.786874</td>\n",
       "      <td>-0.135374</td>\n",
       "      <td>0.845853</td>\n",
       "      <td>-5.201098</td>\n",
       "      <td>-0.397249</td>\n",
       "      <td>-0.755364</td>\n",
       "      <td>-1.867080</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.323619</td>\n",
       "      <td>-22.983434</td>\n",
       "      <td>19.214541</td>\n",
       "      <td>8.592070</td>\n",
       "      <td>-6.565695</td>\n",
       "      <td>9.690675</td>\n",
       "      <td>-4.462943</td>\n",
       "      <td>-9.763791</td>\n",
       "      <td>-11.033206</td>\n",
       "      <td>-0.207197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19466</th>\n",
       "      <td>0.464844</td>\n",
       "      <td>5210.244186</td>\n",
       "      <td>17.172745</td>\n",
       "      <td>-4.287327</td>\n",
       "      <td>-0.035162</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>-2.851425</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>-0.839526</td>\n",
       "      <td>-0.143111</td>\n",
       "      <td>...</td>\n",
       "      <td>19.401534</td>\n",
       "      <td>15.638111</td>\n",
       "      <td>-15.014686</td>\n",
       "      <td>11.238390</td>\n",
       "      <td>-13.355906</td>\n",
       "      <td>-1.986952</td>\n",
       "      <td>13.559861</td>\n",
       "      <td>-19.614411</td>\n",
       "      <td>-4.226408</td>\n",
       "      <td>0.204496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19467</th>\n",
       "      <td>0.172414</td>\n",
       "      <td>5263.541985</td>\n",
       "      <td>11.854728</td>\n",
       "      <td>-2.310506</td>\n",
       "      <td>-0.673756</td>\n",
       "      <td>4.553264</td>\n",
       "      <td>-0.543732</td>\n",
       "      <td>2.022744</td>\n",
       "      <td>-0.174248</td>\n",
       "      <td>-1.116603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756128</td>\n",
       "      <td>1.302461</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>12.173344</td>\n",
       "      <td>-5.296037</td>\n",
       "      <td>7.027503</td>\n",
       "      <td>5.064962</td>\n",
       "      <td>3.050112</td>\n",
       "      <td>6.037015</td>\n",
       "      <td>-0.428344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19468 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1          2         3         4         5   \\\n",
       "0      0.437773  89446.786957   6.728266 -2.205232 -0.935654  0.414398   \n",
       "1      0.513393   3834.459649  10.334824 -3.120607 -0.430606 -0.189135   \n",
       "2      0.347561  10888.293103   4.592510 -3.190515 -1.007697  3.566104   \n",
       "3      0.355908  58446.510204   9.826862 -1.359778  1.603947  1.285903   \n",
       "4      0.482927  32380.040541  17.349594  1.228321 -0.375397 -2.452161   \n",
       "...         ...           ...        ...       ...       ...       ...   \n",
       "19463  0.437773  89446.786957   6.728266 -2.205232 -0.935654  0.414398   \n",
       "19464  0.181338   3442.966292   1.844459  2.867678  2.187282  4.048394   \n",
       "19465  0.500595   4623.850480  14.910786 -4.786874 -0.135374  0.845853   \n",
       "19466  0.464844   5210.244186  17.172745 -4.287327 -0.035162  0.498981   \n",
       "19467  0.172414   5263.541985  11.854728 -2.310506 -0.673756  4.553264   \n",
       "\n",
       "             6         7         8         9   ...         67         68  \\\n",
       "0     -0.722790 -0.170461 -0.396117 -0.478514  ...  -5.375868 -15.747827   \n",
       "1     -1.491082 -1.161160 -0.883617  1.476626  ... -13.424211 -14.681874   \n",
       "2     -0.926311  0.800057 -1.553255  0.150828  ...   2.404554  -7.091844   \n",
       "3     -1.549141  1.407438 -0.527707 -1.540423  ...   6.423792   0.420492   \n",
       "4     -3.844825 -0.479502 -2.034023 -1.296189  ...  -1.284498   9.315584   \n",
       "...         ...       ...       ...       ...  ...        ...        ...   \n",
       "19463 -0.722790 -0.170461 -0.396117 -0.478514  ...  -9.846691  -2.671703   \n",
       "19464 -1.494160  0.845086  1.209595 -0.510142  ...   4.637885   3.869178   \n",
       "19465 -5.201098 -0.397249 -0.755364 -1.867080  ...  -2.323619 -22.983434   \n",
       "19466 -2.851425  0.040663 -0.839526 -0.143111  ...  19.401534  15.638111   \n",
       "19467 -0.543732  2.022744 -0.174248 -1.116603  ...  -0.756128   1.302461   \n",
       "\n",
       "              69         70         71        72         73         74  \\\n",
       "0      10.470771   0.691198  -2.789990  1.827842  -0.277631   1.139680   \n",
       "1       1.536202   2.356138   5.213597  5.147564   7.545617   5.880928   \n",
       "2      -5.271067  -4.057229  -2.413814  0.685560  14.102049  15.216167   \n",
       "3       9.965358  -4.019853  17.191104  1.620610   9.487975   2.405741   \n",
       "4     -10.445529  11.428464   0.595655  1.485687  -1.503689   2.343183   \n",
       "...          ...        ...        ...       ...        ...        ...   \n",
       "19463  -0.628226  18.510978 -10.815182 -0.016847  -7.861359  -7.371767   \n",
       "19464   2.353058  -4.430796   3.717093 -6.779565   9.317777  -3.288596   \n",
       "19465  19.214541   8.592070  -6.565695  9.690675  -4.462943  -9.763791   \n",
       "19466 -15.014686  11.238390 -13.355906 -1.986952  13.559861 -19.614411   \n",
       "19467   0.011953  12.173344  -5.296037  7.027503   5.064962   3.050112   \n",
       "\n",
       "              75        76  \n",
       "0       3.945075 -0.574410  \n",
       "1      -2.953583 -0.545915  \n",
       "2       2.129391 -0.436742  \n",
       "3       9.072886  0.547553  \n",
       "4       0.056319 -0.736785  \n",
       "...          ...       ...  \n",
       "19463 -34.196477  0.632159  \n",
       "19464  -0.027603 -0.035675  \n",
       "19465 -11.033206 -0.207197  \n",
       "19466  -4.226408  0.204496  \n",
       "19467   6.037015 -0.428344  \n",
       "\n",
       "[19468 rows x 77 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c74d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
